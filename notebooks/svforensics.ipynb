{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uU3OzjEgIOP5"
      },
      "outputs": [],
      "source": [
        "# @title (C√©lula 1) Instalar o Pacote SVforensics\n",
        "# @markdown Esta c√©lula instala o pacote de software necess√°rio diretamente do GitHub.\n",
        "# @markdown **Para colaboradores externos:** Cole seu token de acesso fornecido oficialmente no campo abaixo.\n",
        "# @markdown **Para uso interno (Pol√≠cia Cient√≠fica):** Deixe o campo vazio.\n",
        "# @markdown Pode levar um ou dois minutos para concluir.\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **Token de Acesso (apenas para colaboradores externos):**\n",
        "TOKEN = \"\" # @param {type:\"string\"}\n",
        "\n",
        "print(\"Instalando SVforensics...\")\n",
        "\n",
        "# Configurar URL de instala√ß√£o baseada no token\n",
        "if TOKEN.strip():\n",
        "    # Para colaboradores externos com token\n",
        "    install_url = f\"git+https://{TOKEN}@github.com/sepai-dev/SVforensics.git\"\n",
        "    print(\"üîê Usando autentica√ß√£o via token para colaborador externo...\")\n",
        "else:\n",
        "    # Para uso interno (conta organizacional)\n",
        "    install_url = \"git+https://github.com/sepai-dev/SVforensics.git\"\n",
        "    print(\"üè¢ Usando acesso institucional interno...\")\n",
        "\n",
        "# -q para menos output, --no-cache-dir pode ajudar a evitar problemas de cache no Colab\n",
        "%pip install --no-cache-dir {install_url} -q\n",
        "print(\"‚úÖ Instala√ß√£o conclu√≠da!\")\n",
        "\n",
        "# Importar bibliotecas padr√£o que vamos precisar\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "# Configurar logging b√°sico\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(\"SVF_Colab\")\n",
        "\n",
        "print(\"Bibliotecas padr√£o importadas e logging configurado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XxeRlJr0M8qB"
      },
      "outputs": [],
      "source": [
        "# @title (C√©lula 2) Downloads Essenciais e Leitura de Configura√ß√£o\n",
        "# @markdown Baixa arquivos de configura√ß√£o, o modelo de embedding E os dados da popula√ß√£o de refer√™ncia.\n",
        "# @markdown L√™ as configura√ß√µes para uso nas c√©lulas seguintes.\n",
        "\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from huggingface_hub import hf_hub_download\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Configurar logging b√°sico\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(\"SVF_Colab_Downloads\")\n",
        "\n",
        "# --- 1. Baixar Arquivos de Configura√ß√£o ---\n",
        "logger.info(\"Iniciando download dos arquivos de configura√ß√£o...\")\n",
        "\n",
        "# Usar o mesmo token da c√©lula anterior se dispon√≠vel (para colaboradores externos)\n",
        "try:\n",
        "    auth_token = TOKEN.strip() if 'TOKEN' in globals() and TOKEN.strip() else None\n",
        "except NameError:\n",
        "    auth_token = None\n",
        "\n",
        "# Configurar headers de autentica√ß√£o se necess√°rio\n",
        "headers = {}\n",
        "if auth_token:\n",
        "    headers[\"Authorization\"] = f\"token {auth_token}\"\n",
        "    logger.info(\"üîê Usando autentica√ß√£o para download de arquivos de configura√ß√£o\")\n",
        "else:\n",
        "    logger.info(\"üè¢ Usando acesso institucional para download de arquivos de configura√ß√£o\")\n",
        "\n",
        "config_dir = \"config\"\n",
        "os.makedirs(config_dir, exist_ok=True)\n",
        "config_files_urls = {\n",
        "    \"svforensics.json\": \"https://raw.githubusercontent.com/sepai-dev/SVforensics/refs/heads/main/config/svforensics.json\",\n",
        "    \"download_info.json\": \"https://raw.githubusercontent.com/sepai-dev/SVforensics/refs/heads/main/config/download_info.json\",\n",
        "    # <<< ADICIONADO plot_config.json >>>\n",
        "    \"plot_config.json\": \"https://raw.githubusercontent.com/sepai-dev/SVforensics/refs/heads/main/config/plot_config.json\"\n",
        "}\n",
        "config_paths = {}\n",
        "config_download_ok = True\n",
        "for filename, url in config_files_urls.items():\n",
        "    filepath = Path(config_dir) / filename\n",
        "    try:\n",
        "        logger.info(f\"Baixando {filename} de {url}...\")\n",
        "        response = requests.get(url, headers=headers, timeout=20)\n",
        "        response.raise_for_status()\n",
        "        with open(filepath, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        config_paths[filename] = str(filepath)\n",
        "        logger.info(f\"- {filename} baixado com sucesso para {filepath}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Erro ao baixar {filename}: {e}\")\n",
        "        config_download_ok = False\n",
        "\n",
        "if not config_download_ok:\n",
        "    raise RuntimeError(\"Falha ao baixar arquivos de configura√ß√£o essenciais.\")\n",
        "logger.info(\"Download dos arquivos de configura√ß√£o conclu√≠do.\")\n",
        "\n",
        "# --- 2. Ler Configura√ß√£o Principal ---\n",
        "logger.info(\"Lendo configura√ß√£o principal (svforensics.json)...\")\n",
        "config_main_path = config_paths.get(\"svforensics.json\")\n",
        "try:\n",
        "    with open(config_main_path, 'r') as f:\n",
        "        svf_config = json.load(f)\n",
        "    logger.info(\"Configura√ß√£o principal lida com sucesso.\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Falha ao ler o arquivo de configura√ß√£o principal '{config_main_path}': {e}\")\n",
        "\n",
        "# --- 3. Baixar Modelo de Embedding ---\n",
        "logger.info(\"Iniciando download do modelo de embedding...\")\n",
        "model_config = svf_config.get(\"model\", {})\n",
        "paths_config = svf_config.get(\"paths\", {})\n",
        "model_repo = model_config.get(\"repository\", \"Jenthe/ECAPA2\")\n",
        "model_filename = model_config.get(\"filename\", \"ecapa2.pt\")\n",
        "cache_dir = paths_config.get(\"models_cache_dir\", \"files/downloads/models\")\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "try:\n",
        "    logger.info(f\"Baixando/verificando modelo '{model_filename}' de '{model_repo}' para '{cache_dir}'...\")\n",
        "    start_time = time.time()\n",
        "    model_path = hf_hub_download(repo_id=model_repo, filename=model_filename, cache_dir=cache_dir)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    logger.info(f\"Modelo de embedding dispon√≠vel em: {model_path} (Download/Verifica√ß√£o levou {elapsed_time:.2f}s)\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Falha ao baixar o modelo de embedding: {e}\")\n",
        "\n",
        "# --- 4. Baixar Dados da Popula√ß√£o de Refer√™ncia ---\n",
        "logger.info(\"Iniciando download dos dados da popula√ß√£o de refer√™ncia (definidos em download_info.json)...\")\n",
        "print(\"\\n‚è≥ Baixando dados da popula√ß√£o de refer√™ncia (pode demorar)...\")\n",
        "try:\n",
        "    from svforensics import download\n",
        "    output_downloads_dir = paths_config.get(\"downloads_dir\", \"files/downloads\")\n",
        "    download_info_file_path = config_paths.get(\"download_info.json\", \"config/download_info.json\") # Usa o baixado\n",
        "\n",
        "    if not os.path.exists(download_info_file_path):\n",
        "         logger.warning(f\"Arquivo download_info.json n√£o encontrado em {download_info_file_path}, pulando downloads adicionais.\")\n",
        "         print(\"‚ö†Ô∏è Arquivo de informa√ß√µes de download n√£o encontrado. Dados de refer√™ncia podem n√£o ter sido baixados.\")\n",
        "    else:\n",
        "        # Verifica se a fun√ß√£o cli_main existe antes de chamar\n",
        "        if hasattr(download, 'cli_main') and callable(getattr(download, 'cli_main')):\n",
        "             download.cli_main(args=[\n",
        "                 '--config', download_info_file_path,\n",
        "                 '--output-dir', output_downloads_dir\n",
        "             ])\n",
        "             logger.info(f\"Comando de download executado para '{output_downloads_dir}'.\")\n",
        "             print(\"‚úÖ Download dos dados de refer√™ncia conclu√≠do (ou verificado).\")\n",
        "        else:\n",
        "             logger.error(\"Fun√ß√£o download.cli_main n√£o encontrada. N√£o foi poss√≠vel executar downloads adicionais.\")\n",
        "             print(\"‚ùå Erro: Fun√ß√£o de download n√£o encontrada.\")\n",
        "\n",
        "except ImportError:\n",
        "    logger.error(\"Erro ao importar o m√≥dulo 'download'.\")\n",
        "    print(\"‚ùå Erro: N√£o foi poss√≠vel executar o download dos dados de refer√™ncia.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Erro durante o download dos dados de refer√™ncia: {e}\", exc_info=True)\n",
        "    print(\"‚ùå Erro durante o download dos dados de refer√™ncia.\")\n",
        "\n",
        "# --- 5. Salvar Configura√ß√µes ---\n",
        "logger.info(\"Salvando configura√ß√µes lidas para uso posterior...\")\n",
        "%store svf_config paths_config config_paths model_repo model_filename cache_dir\n",
        "logger.info(\"Configura√ß√µes salvas.\")\n",
        "\n",
        "print(\"\\nConfigura√ß√£o inicial e downloads essenciais conclu√≠dos!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t-9aRqNqSA4C"
      },
      "outputs": [],
      "source": [
        "# @title (C√©lula 3) Mesclar Embeddings e Metadados da Refer√™ncia\n",
        "# @markdown Combina os embeddings e metadados da popula√ß√£o de refer√™ncia baixados.\n",
        "\n",
        "import os\n",
        "import logging\n",
        "\n",
        "# Usar o logger configurado\n",
        "logger = logging.getLogger(\"SVF_Colab_MergeRef\")\n",
        "\n",
        "# --- 1. Recuperar Vari√°veis Salvas ---\n",
        "logger.info(\"Recuperando configura√ß√µes salvas...\")\n",
        "try:\n",
        "    %store -r svf_config\n",
        "    %store -r paths_config\n",
        "    logger.info(\"Vari√°veis recuperadas com sucesso.\")\n",
        "except KeyError as e:\n",
        "    raise RuntimeError(f\"Erro: Vari√°vel '{e}' n√£o encontrada. Execute a C√©lula 2 primeiro.\")\n",
        "\n",
        "# --- 2. Importar Funcionalidade de Merge ---\n",
        "logger.info(\"Importando a funcionalidade de merge...\")\n",
        "try:\n",
        "    from svforensics import metadata_embedding_merge\n",
        "    logger.info(\"M√≥dulo 'metadata_embedding_merge' importado.\")\n",
        "except ImportError:\n",
        "    raise RuntimeError(\"Erro ao importar 'metadata_embedding_merge'. Verifique a instala√ß√£o.\")\n",
        "\n",
        "# --- 3. Definir Caminhos de Entrada e Sa√≠da ---\n",
        "logger.info(\"Definindo caminhos para o merge...\")\n",
        "# Pegar caminhos dos arquivos baixados na C√©lula 2 da config\n",
        "ref_embedding_file = paths_config.get(\"raw_embeddings_file\", \"files/downloads/vox1_test_whatsapp_ecapa2.pth\")\n",
        "ref_metadata_file = paths_config.get(\"metadata_file\", \"files/downloads/vox1_meta.csv\")\n",
        "# Definir prefixo de sa√≠da para o arquivo mesclado (.pth ser√° adicionado)\n",
        "output_prefix = paths_config.get(\"output_prefix\", \"files/generated/metadata_embeddings/processed_embeddings\")\n",
        "# Colunas a remover (da config)\n",
        "drop_columns = svf_config.get(\"processing\", {}).get(\"drop_columns\", None)\n",
        "\n",
        "# Verificar se os arquivos de entrada existem\n",
        "if not os.path.exists(ref_embedding_file) or not os.path.exists(ref_metadata_file):\n",
        "    logger.error(f\"Arquivos de entrada para merge n√£o encontrados: Emb='{ref_embedding_file}', Meta='{ref_metadata_file}'\")\n",
        "    raise FileNotFoundError(\"Arquivos de refer√™ncia baixados na C√©lula 2 n√£o encontrados.\")\n",
        "\n",
        "logger.info(f\"Arquivo de embeddings de refer√™ncia: {ref_embedding_file}\")\n",
        "logger.info(f\"Arquivo de metadados de refer√™ncia: {ref_metadata_file}\")\n",
        "logger.info(f\"Prefixo de sa√≠da para dados mesclados: {output_prefix}\")\n",
        "\n",
        "# Garantir que o diret√≥rio de sa√≠da exista\n",
        "os.makedirs(os.path.dirname(output_prefix), exist_ok=True)\n",
        "\n",
        "# --- 4. Executar Merge ---\n",
        "logger.info(\"Iniciando o merge dos dados de refer√™ncia...\")\n",
        "print(\"\\n‚è≥ Mesclando dados da popula√ß√£o de refer√™ncia...\")\n",
        "try:\n",
        "    # Usar a fun√ß√£o main do m√≥dulo, que encapsula a l√≥gica\n",
        "    merged_df = metadata_embedding_merge.main(\n",
        "        embedding_file=ref_embedding_file,\n",
        "        metadata_file=ref_metadata_file,\n",
        "        output_prefix=output_prefix,\n",
        "        test_file=None, # N√£o estamos filtrando por test list aqui\n",
        "        drop_columns=drop_columns, # Usa as colunas da config\n",
        "        save_output=True # Queremos salvar o .pth mesclado\n",
        "    )\n",
        "    output_merged_file = f\"{output_prefix}.pth\" # Caminho do arquivo salvo\n",
        "    logger.info(f\"Merge conclu√≠do. Dados mesclados salvos em {output_merged_file}\")\n",
        "    print(f\"‚úÖ Merge dos dados de refer√™ncia conclu√≠do. Salvo em: {output_merged_file}\")\n",
        "\n",
        "    # Salvar caminho do arquivo mesclado para a pr√≥xima c√©lula\n",
        "    %store output_merged_file\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(f\"Erro durante o merge: {e}\", exc_info=True)\n",
        "    print(\"‚ùå Erro durante o merge dos dados de refer√™ncia. Verifique os logs.\")\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "73kdLe5EVLOE"
      },
      "outputs": [],
      "source": [
        "# @title (C√©lula 4) Gerar Lista de Teste da Popula√ß√£o de Refer√™ncia\n",
        "# @markdown Cria pares de compara√ß√£o (mesmo/diferente locutor) da popula√ß√£o de refer√™ncia.\n",
        "# @markdown **Requer que voc√™ selecione o g√™nero abaixo.**\n",
        "\n",
        "import os\n",
        "import logging\n",
        "from pathlib import Path # Importar Path\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Selecione o G√™nero para a Lista de Teste:\n",
        "# @markdown A lista de teste ser√° criada usando apenas locutores do g√™nero selecionado.\n",
        "selected_gender = \"m\" # @param [\"m\", \"f\"] {allow-input: false}\n",
        "# @markdown ---\n",
        "\n",
        "# Usar o logger configurado\n",
        "logger = logging.getLogger(\"SVF_Colab_Testlist\")\n",
        "\n",
        "# --- 1. Recuperar Vari√°veis Salvas ---\n",
        "logger.info(\"Recuperando configura√ß√µes e caminho dos dados mesclados...\")\n",
        "try:\n",
        "    %store -r svf_config\n",
        "    %store -r paths_config\n",
        "    # Corre√ß√£o: Remover coment√°rio desta linha\n",
        "    %store -r output_merged_file\n",
        "    logger.info(\"Vari√°veis recuperadas com sucesso.\")\n",
        "except KeyError as e:\n",
        "    raise RuntimeError(f\"Erro: Vari√°vel '{e}' n√£o encontrada. Execute as C√©lulas 2 e 3 primeiro.\")\n",
        "\n",
        "# --- 2. Importar Funcionalidade de Testlist ---\n",
        "logger.info(\"Importando a funcionalidade de gera√ß√£o de testlist...\")\n",
        "try:\n",
        "    from svforensics import testlists\n",
        "    logger.info(\"M√≥dulo 'testlists' importado.\")\n",
        "except ImportError:\n",
        "    raise RuntimeError(\"Erro ao importar 'testlists'. Verifique a instala√ß√£o.\")\n",
        "\n",
        "# --- 3. Definir Par√¢metros ---\n",
        "logger.info(\"Definindo par√¢metros para gera√ß√£o da testlist...\")\n",
        "merged_embeddings_file = output_merged_file\n",
        "output_testlist_prefix = paths_config.get(\"test_list_prefix\", \"files/generated/testlists/test_list\")\n",
        "testlist_config = svf_config.get(\"testlists\", {})\n",
        "n_pos = testlist_config.get(\"n_pos\", 1)\n",
        "n_neg = testlist_config.get(\"n_neg\", 1)\n",
        "different_videos = testlist_config.get(\"different_videos\", True)\n",
        "test_prop = testlist_config.get(\"test_prop\", 0.5)\n",
        "random_state = testlist_config.get(\"random_seed\", 42)\n",
        "gender = selected_gender\n",
        "\n",
        "# Log dos par√¢metros (opcional, pode remover para menos verbosidade)\n",
        "# logger.info(f\"G√™nero selecionado para a lista: {gender}\")\n",
        "# logger.info(f\"Arquivo de embeddings mesclados (entrada): {merged_embeddings_file}\")\n",
        "# logger.info(f\"Prefixo de sa√≠da para a lista de teste: {output_testlist_prefix}\")\n",
        "# logger.info(f\"n_pos={n_pos}, n_neg={n_neg}, different_videos={different_videos}, test_prop={test_prop}, seed={random_state}\")\n",
        "\n",
        "if not os.path.exists(merged_embeddings_file):\n",
        "    raise FileNotFoundError(f\"Arquivo de embeddings mesclados n√£o encontrado: {merged_embeddings_file}\")\n",
        "\n",
        "os.makedirs(Path(output_testlist_prefix).parent, exist_ok=True) # Usar Path\n",
        "\n",
        "# --- 4. Executar Gera√ß√£o da Testlist ---\n",
        "# Manter o print inicial para o usu√°rio saber o que est√° acontecendo\n",
        "print(f\"\\n‚è≥ Gerando lista de teste para g√™nero '{gender}'...\")\n",
        "try:\n",
        "    generated_testlist_path = testlists.create_test_lists(\n",
        "        gender=gender,\n",
        "        embeddings_file=merged_embeddings_file,\n",
        "        output_prefix=output_testlist_prefix,\n",
        "        n_pos=n_pos,\n",
        "        n_neg=n_neg,\n",
        "        different_videos=different_videos,\n",
        "        test_prop=test_prop,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    logger.info(f\"Gera√ß√£o da lista de teste conclu√≠da. Salva em {generated_testlist_path}\")\n",
        "    # Manter o print de sucesso para o usu√°rio\n",
        "    print(f\"‚úÖ Lista de teste gerada com sucesso! Salva em: {generated_testlist_path}\")\n",
        "\n",
        "    %store generated_testlist_path\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(f\"Erro durante a gera√ß√£o da lista de teste: {e}\", exc_info=True)\n",
        "    # Manter o print de erro para o usu√°rio\n",
        "    print(\"‚ùå Erro durante a gera√ß√£o da lista de teste. Verifique os logs.\")\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b4R5JFSiWnxr"
      },
      "outputs": [],
      "source": [
        "# @title (C√©lula 5) Upload dos Arquivos de √Åudio do Caso\n",
        "# @markdown Fa√ßa o upload dos arquivos 'questionado(s)' e 'refer√™ncia(s)' **deste caso espec√≠fico**.\n",
        "# @markdown Os arquivos ser√£o movidos para os diret√≥rios corretos.\n",
        "# @markdown ---\n",
        "# @markdown 1. **Questionados:** Clique em \"Escolher arquivos\" e selecione **todos** os arquivos questionados.\n",
        "# @markdown 2. **Refer√™ncia:** Clique em \"Escolher arquivos\" novamente e selecione **todos** os arquivos de refer√™ncia.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "import logging\n",
        "import glob\n",
        "\n",
        "# Usar o logger configurado\n",
        "logger = logging.getLogger(\"SVF_Colab_Upload_Caso\")\n",
        "\n",
        "# --- Nomes Definidos para os Diret√≥rios do Caso ---\n",
        "dir_caso_q = \"audios_caso_questionados\"\n",
        "dir_caso_r = \"audios_caso_referencia\"\n",
        "logger.info(f\"Diret√≥rios de upload do caso definidos: '{dir_caso_q}', '{dir_caso_r}'\")\n",
        "\n",
        "# --- Limpeza Pr√©via ---\n",
        "for d in [dir_caso_q, dir_caso_r]:\n",
        "    if os.path.exists(d):\n",
        "        logger.warning(f\"Limpando diret√≥rio de caso existente: {d}\")\n",
        "        shutil.rmtree(d)\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "    logger.info(f\"Diret√≥rio de caso criado/limpo: {d}\")\n",
        "\n",
        "def upload_e_renomear(diretorio_destino, tipo_arquivo_log):\n",
        "    \"\"\"Fun√ß√£o auxiliar para solicitar upload e MOVER usando os.rename.\"\"\"\n",
        "    print(f\"\\n‚û°Ô∏è Por favor, fa√ßa o upload do(s) arquivo(s) de √°udio {tipo_arquivo_log.upper()} (DO CASO):\")\n",
        "    uploaded_filenames = []\n",
        "    try:\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            logger.warning(f\"Nenhum arquivo {tipo_arquivo_log} do caso foi enviado.\")\n",
        "            print(f\"‚ö†Ô∏è Nenhum arquivo {tipo_arquivo_log} selecionado.\")\n",
        "            return False, 0, []\n",
        "        else:\n",
        "            count_moved = 0\n",
        "            uploaded_filenames = list(uploaded.keys())\n",
        "            for filename in uploaded_filenames:\n",
        "                source_path_str = filename\n",
        "                dest_path_str = str(Path(diretorio_destino) / filename)\n",
        "                try:\n",
        "                    os.rename(source_path_str, dest_path_str)\n",
        "                    logger.info(f\"Arquivo {tipo_arquivo_log} '{filename}' movido para '{dest_path_str}'.\")\n",
        "                    count_moved += 1\n",
        "                except OSError as e:\n",
        "                    logger.error(f\"Erro ao MOVER (os.rename) o arquivo {filename} para {dest_path_str}: {e}\")\n",
        "                    print(f\"‚ùå Erro ao mover {filename}.\")\n",
        "                    if os.path.exists(source_path_str):\n",
        "                         logger.warning(f\"Arquivo {filename} ainda existe na raiz ap√≥s falha no os.rename.\")\n",
        "\n",
        "            if count_moved == len(uploaded):\n",
        "                print(f\"‚úÖ {count_moved} arquivo(s) {tipo_arquivo_log} do caso processado(s) com sucesso.\")\n",
        "                return True, count_moved, uploaded_filenames\n",
        "            else:\n",
        "                 print(f\"‚ö†Ô∏è {count_moved}/{len(uploaded)} arquivo(s) {tipo_arquivo_log} do caso processado(s). Verifique os logs.\")\n",
        "                 return False, count_moved, uploaded_filenames\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Erro durante o processo de upload/movimenta√ß√£o para {tipo_arquivo_log}: {e}\")\n",
        "        print(f\"‚ùå Ocorreu um erro inesperado durante o upload.\")\n",
        "        return False, 0, uploaded_filenames\n",
        "\n",
        "# --- Executar Upload ---\n",
        "upload_ok_q, count_q, files_q = upload_e_renomear(dir_caso_q, \"questionado(s)\")\n",
        "upload_ok_r, count_r, files_r = False, 0, []\n",
        "if upload_ok_q and count_q > 0:\n",
        "    upload_ok_r, count_r, files_r = upload_e_renomear(dir_caso_r, \"refer√™ncia\")\n",
        "elif not upload_ok_q:\n",
        "     print(\"\\nUpload de arquivos questionados do caso falhou ou foi cancelado.\")\n",
        "else:\n",
        "    print(\"\\nNenhum arquivo questionado do caso foi selecionado.\")\n",
        "\n",
        "# --- Verifica√ß√£o Final e Armazenamento ---\n",
        "upload_geral_ok = upload_ok_q and count_q > 0 and upload_ok_r and count_r > 0\n",
        "\n",
        "if upload_geral_ok:\n",
        "    logger.info(f\"Upload e movimenta√ß√£o do caso conclu√≠dos: {count_q} questionado(s), {count_r} refer√™ncia(s).\")\n",
        "    # Corre√ß√£o: Remover o -q inv√°lido\n",
        "    %store dir_caso_q\n",
        "    %store dir_caso_r\n",
        "    print(\"\\nüéâ Uploads do caso conclu√≠dos com sucesso!\")\n",
        "else:\n",
        "    logger.error(\"Upload do caso falhou ou arquivos essenciais n√£o foram enviados/movidos.\")\n",
        "    print(\"\\n‚ùå Aten√ß√£o: Upload do caso n√£o conclu√≠do corretamente.\")\n",
        "\n",
        "# --- LIMPEZA FINAL DA RAIZ ---\n",
        "logger.info(\"Limpando arquivos tempor√°rios da pasta raiz...\")\n",
        "files_to_clean = files_q + files_r\n",
        "cleaned_count = 0\n",
        "errors_cleaning = 0\n",
        "\n",
        "for filename in files_to_clean:\n",
        "     if os.path.exists(filename):\n",
        "          try:\n",
        "               os.remove(filename)\n",
        "               logger.info(f\"Arquivo remanescente '{filename}' removido da raiz.\")\n",
        "               cleaned_count += 1\n",
        "          except OSError as e:\n",
        "               logger.error(f\"Erro ao remover arquivo remanescente '{filename}' da raiz: {e}\")\n",
        "               errors_cleaning += 1\n",
        "\n",
        "extra_ogg_files = glob.glob(\"*.ogg\")\n",
        "for extra_file in extra_ogg_files:\n",
        "     if os.path.exists(extra_file):\n",
        "          logger.warning(f\"Encontrado arquivo .ogg inesperado '{extra_file}' na raiz. Tentando remover...\")\n",
        "          try:\n",
        "               os.remove(extra_file)\n",
        "               logger.info(f\"Arquivo extra '{extra_file}' removido da raiz.\")\n",
        "               cleaned_count += 1\n",
        "          except OSError as e:\n",
        "               logger.error(f\"Erro ao remover arquivo extra '{extra_file}' da raiz: {e}\")\n",
        "               errors_cleaning += 1\n",
        "\n",
        "logger.info(f\"Limpeza da raiz finalizada. Removidos: {cleaned_count}, Erros: {errors_cleaning}\")\n",
        "\n",
        "if not upload_geral_ok:\n",
        "     print(\"\\nLembrete: O upload n√£o foi totalmente bem-sucedido.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YCmktf7aYe_m"
      },
      "outputs": [],
      "source": [
        "# @title (C√©lula 6) Preparar Arquivos de √Åudio do Caso\n",
        "# @markdown Processa os √°udios originais do caso, salvando chunks diretamente em 'probe' e 'reference'.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import shutil\n",
        "import glob # Para encontrar arquivos\n",
        "\n",
        "# Usar o logger configurado\n",
        "logger = logging.getLogger(\"SVF_Colab_AudioPrep_Caso\")\n",
        "\n",
        "# --- 1. Recuperar Vari√°veis Salvas ---\n",
        "logger.info(\"Recuperando vari√°veis salvas...\")\n",
        "try:\n",
        "    # Corre√ß√£o: Remover coment√°rios das linhas %store -r\n",
        "    %store -r dir_caso_q\n",
        "    %store -r dir_caso_r\n",
        "    %store -r svf_config\n",
        "    %store -r paths_config\n",
        "    logger.info(\"Vari√°veis recuperadas com sucesso.\")\n",
        "except KeyError as e:\n",
        "    raise RuntimeError(f\"Erro: Vari√°vel '{e}' n√£o encontrada. Execute as C√©lulas 2 e 5 primeiro.\")\n",
        "\n",
        "# --- 2. Importar Fun√ß√µes de Prepara√ß√£o ---\n",
        "logger.info(\"Importando fun√ß√µes de prepara√ß√£o de √°udio...\")\n",
        "try:\n",
        "    from svforensics.audioprep import process_audio_file, DEFAULT_AUDIO_EXTENSIONS, DEFAULT_SAMPLE_RATE, DEFAULT_CHUNK_DURATION, DEFAULT_FADE_DURATION\n",
        "    logger.info(\"Fun√ß√£o 'process_audio_file' e constantes importadas.\")\n",
        "except ImportError as e:\n",
        "    raise RuntimeError(f\"Erro ao importar de svforensics.audioprep: {e}.\")\n",
        "\n",
        "# --- 3. Definir Par√¢metros e Caminhos de Sa√≠da ---\n",
        "logger.info(\"Definindo par√¢metros e caminhos de sa√≠da...\")\n",
        "\n",
        "audio_config = svf_config.get(\"audio\", {})\n",
        "sample_rate = audio_config.get(\"sample_rate\", DEFAULT_SAMPLE_RATE)\n",
        "chunk_duration = audio_config.get(\"chunk_duration\", DEFAULT_CHUNK_DURATION)\n",
        "fade_duration = audio_config.get(\"fade_duration\", DEFAULT_FADE_DURATION)\n",
        "min_chunk_duration = audio_config.get(\"min_chunk_duration\")\n",
        "output_format = audio_config.get(\"output_format\", \"wav\")\n",
        "audio_extensions = audio_config.get(\"audio_extensions\", DEFAULT_AUDIO_EXTENSIONS)\n",
        "\n",
        "output_probe_chunk_dir = Path(paths_config.get(\"probe_processed_dir\", \"files/generated/case/audio_chunks/probe\"))\n",
        "output_ref_chunk_dir = Path(paths_config.get(\"reference_processed_dir\", \"files/generated/case/audio_chunks/reference\"))\n",
        "logger.info(f\"Diret√≥rio de sa√≠da para chunks Questionados: {output_probe_chunk_dir}\")\n",
        "logger.info(f\"Diret√≥rio de sa√≠da para chunks Refer√™ncia: {output_ref_chunk_dir}\")\n",
        "\n",
        "# --- 4. Limpar Diret√≥rios de Sa√≠da e Processar Arquivos ---\n",
        "all_processed_chunks = []\n",
        "total_probe_chunks = 0\n",
        "total_ref_chunks = 0\n",
        "\n",
        "# Manter o print para feedback\n",
        "print(\"\\n‚è≥ Iniciando prepara√ß√£o dos √°udios do caso (processamento direto)...\")\n",
        "\n",
        "for input_dir_name, output_chunk_dir, type_label in [\n",
        "    (dir_caso_q, output_probe_chunk_dir, \"Questionado\"),\n",
        "    (dir_caso_r, output_ref_chunk_dir, \"Refer√™ncia\")\n",
        "]:\n",
        "    logger.info(f\"Processando tipo: {type_label}\")\n",
        "    if output_chunk_dir.exists():\n",
        "        logger.warning(f\"Limpando diret√≥rio de sa√≠da existente: {output_chunk_dir}\")\n",
        "        shutil.rmtree(output_chunk_dir)\n",
        "    output_chunk_dir.mkdir(parents=True, exist_ok=True)\n",
        "    logger.info(f\"Diret√≥rio de sa√≠da '{output_chunk_dir}' limpo/criado.\")\n",
        "\n",
        "    input_files = []\n",
        "    for ext in audio_extensions:\n",
        "        pattern = str(Path(input_dir_name) / f\"*{ext}\")\n",
        "        input_files.extend(glob.glob(pattern))\n",
        "\n",
        "    if not input_files:\n",
        "        logger.warning(f\"Nenhum arquivo de √°udio encontrado em '{input_dir_name}' com extens√µes {audio_extensions}\")\n",
        "        continue\n",
        "    logger.info(f\"Encontrados {len(input_files)} arquivos em '{input_dir_name}'. Processando...\")\n",
        "\n",
        "    processed_count_type = 0\n",
        "    for audio_file in input_files:\n",
        "        try:\n",
        "            chunk_files = process_audio_file(\n",
        "                audio_file=audio_file,\n",
        "                output_dir=str(output_chunk_dir),\n",
        "                sample_rate=sample_rate,\n",
        "                chunk_duration=chunk_duration,\n",
        "                fade_duration=fade_duration,\n",
        "                min_chunk_duration=min_chunk_duration,\n",
        "                format=output_format\n",
        "            )\n",
        "            all_processed_chunks.extend(chunk_files)\n",
        "            processed_count_type += len(chunk_files)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Falha ao processar arquivo {audio_file}: {e}\", exc_info=True)\n",
        "            # Manter print de erro para o usu√°rio\n",
        "            print(f\"‚ùå Erro ao processar {os.path.basename(audio_file)}. Verifique os logs.\")\n",
        "\n",
        "    logger.info(f\"Processamento do tipo {type_label} conclu√≠do. {processed_count_type} chunks criados.\")\n",
        "    if type_label == \"Questionado\":\n",
        "        total_probe_chunks = processed_count_type\n",
        "    else:\n",
        "        total_ref_chunks = processed_count_type\n",
        "\n",
        "# Manter prints de feedback\n",
        "print(f\"\\n‚úÖ Prepara√ß√£o do caso conclu√≠da!\")\n",
        "print(f\"   - {total_probe_chunks} segmentos de fala extra√≠dos dos √°udios questionados.\")\n",
        "print(f\"   - {total_ref_chunks} segmentos de fala extra√≠dos dos √°udios de refer√™ncia.\")\n",
        "print(f\"   - Arquivos processados (.wav) salvos em: '{output_probe_chunk_dir}' e '{output_ref_chunk_dir}'\")\n",
        "\n",
        "# --- 5. Salvar Caminhos para a Pr√≥xima C√©lula ---\n",
        "parent_chunk_dir_probe_caso = str(output_probe_chunk_dir)\n",
        "parent_chunk_dir_ref_caso = str(output_ref_chunk_dir)\n",
        "\n",
        "logger.info(f\"Salvando caminhos dos diret√≥rios de chunks do caso...\")\n",
        "%store parent_chunk_dir_probe_caso\n",
        "%store parent_chunk_dir_ref_caso\n",
        "logger.info(\"Caminhos salvos.\")\n",
        "\n",
        "# Manter verifica√ß√£o no final (opcional)\n",
        "# print(\"\\nVerificando diret√≥rios de sa√≠da:\")\n",
        "# print(f\"Conte√∫do de '{parent_chunk_dir_probe_caso}':\")\n",
        "# !ls -l \"{parent_chunk_dir_probe_caso}\"\n",
        "# print(f\"\\nConte√∫do de '{parent_chunk_dir_ref_caso}':\")\n",
        "# !ls -l \"{parent_chunk_dir_ref_caso}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8stapJXBdLs2"
      },
      "outputs": [],
      "source": [
        "# @title (C√©lula 7) Extrair Embeddings do Caso\n",
        "# @markdown Analisa os segmentos de √°udio (.wav) do caso e extrai as caracter√≠sticas (embeddings).\n",
        "# @markdown **Este processo pode ser demorado**.\n",
        "\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# Usar o logger configurado\n",
        "logger = logging.getLogger(\"SVF_Colab_Embedding_Caso\")\n",
        "\n",
        "# --- 1. Recuperar Vari√°veis Salvas ---\n",
        "logger.info(\"Recuperando vari√°veis salvas das c√©lulas anteriores...\")\n",
        "try:\n",
        "    # Diret√≥rios PAI contendo subdirs com chunks .wav DO CASO (da C√©lula 6)\n",
        "    %store -r parent_chunk_dir_probe_caso\n",
        "    %store -r parent_chunk_dir_ref_caso\n",
        "    # Nomes dos diret√≥rios originais DO CASO (da C√©lula 5, usados como 'speaker_id')\n",
        "    %store -r dir_caso_q\n",
        "    %store -r dir_caso_r\n",
        "    # Configura√ß√µes e par√¢metros do modelo\n",
        "    %store -r svf_config\n",
        "    %store -r paths_config\n",
        "    %store -r model_repo\n",
        "    %store -r model_filename\n",
        "    %store -r cache_dir\n",
        "    logger.info(\"Vari√°veis recuperadas com sucesso.\")\n",
        "except KeyError as e:\n",
        "    raise RuntimeError(f\"Erro: Vari√°vel '{e}' n√£o encontrada. Execute as c√©lulas anteriores primeiro.\")\n",
        "\n",
        "# --- 2. Importar Classe e Instanciar Extrator ---\n",
        "logger.info(\"Importando e instanciando EmbeddingExtractor...\")\n",
        "try:\n",
        "    from svforensics.case_embeddings import EmbeddingExtractor\n",
        "    start_time = time.time()\n",
        "    embedding_extractor = EmbeddingExtractor(\n",
        "        model_repo=model_repo,\n",
        "        model_filename=model_filename,\n",
        "        cache_dir=cache_dir,\n",
        "        use_half_precision=False\n",
        "    )\n",
        "    _ = embedding_extractor.model # Carrega modelo do cache\n",
        "    elapsed_time = time.time() - start_time\n",
        "    logger.info(f\"EmbeddingExtractor instanciado e modelo carregado de '{cache_dir}' em {elapsed_time:.2f}s.\")\n",
        "    logger.info(f\"Usando dispositivo: {embedding_extractor.device}\")\n",
        "except ImportError:\n",
        "     raise RuntimeError(\"Erro ao importar EmbeddingExtractor.\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Erro ao instanciar EmbeddingExtractor ou carregar modelo: {e}\")\n",
        "\n",
        "# --- 3. Encontrar Arquivos de Chunk do Caso ---\n",
        "logger.info(\"Procurando por arquivos de chunk (.wav) do caso...\")\n",
        "# Usa os diret√≥rios pai _caso salvos na C√©lula 6\n",
        "probe_chunk_files = list(Path(parent_chunk_dir_probe_caso).rglob('*.wav'))\n",
        "ref_chunk_files = list(Path(parent_chunk_dir_ref_caso).rglob('*.wav'))\n",
        "all_chunk_files = probe_chunk_files + ref_chunk_files\n",
        "total_chunks = len(all_chunk_files)\n",
        "logger.info(f\"Encontrados {len(probe_chunk_files)} chunks questionados e {len(ref_chunk_files)} chunks de refer√™ncia do caso.\")\n",
        "logger.info(f\"Total de {total_chunks} chunks do caso a processar.\")\n",
        "\n",
        "if total_chunks == 0:\n",
        "    raise RuntimeError(\"Nenhum arquivo de chunk (.wav) do caso encontrado. A C√©lula 6 falhou?\")\n",
        "\n",
        "# --- 4. Preparar Dicion√°rios de Sa√≠da ---\n",
        "# Usa os nomes dos diret√≥rios originais do CASO como 'speaker_id'\n",
        "probe_speaker_id = Path(dir_caso_q).name\n",
        "ref_speaker_id = Path(dir_caso_r).name\n",
        "probe_embeddings_output = {probe_speaker_id: {}}\n",
        "reference_embeddings_output = {ref_speaker_id: {}}\n",
        "logger.info(f\"Estrutura de sa√≠da preparada para speakers do caso: '{probe_speaker_id}', '{ref_speaker_id}'\")\n",
        "\n",
        "# --- 5. Executar Extra√ß√£o (Loop √önico com Progresso) ---\n",
        "logger.info(\"Iniciando extra√ß√£o de embeddings do caso (loop √∫nico)...\")\n",
        "print(f\"\\n‚è≥ Iniciando extra√ß√£o de embeddings para {total_chunks} arquivos do caso (pode levar v√°rios minutos)...\")\n",
        "\n",
        "extraction_errors = 0\n",
        "start_time_extraction = time.time()\n",
        "for file_path_obj in tqdm(all_chunk_files, desc=\"Extraindo Embeddings (Caso)\", unit=\"file\"):\n",
        "    file_path_str = str(file_path_obj)\n",
        "    try:\n",
        "        embedding = embedding_extractor.extract_embedding(file_path_str)\n",
        "        # Usa os diret√≥rios pai _caso para determinar onde colocar\n",
        "        if file_path_str.startswith(parent_chunk_dir_probe_caso):\n",
        "            probe_embeddings_output[probe_speaker_id][file_path_str] = embedding.cpu()\n",
        "        elif file_path_str.startswith(parent_chunk_dir_ref_caso):\n",
        "            reference_embeddings_output[ref_speaker_id][file_path_str] = embedding.cpu()\n",
        "        else:\n",
        "            logger.warning(f\"Arquivo {file_path_str} n√£o pertence a probe nem reference do caso? Ignorando.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Falha ao extrair embedding de {file_path_str}: {e}\")\n",
        "        extraction_errors += 1\n",
        "\n",
        "elapsed_time_extraction = time.time() - start_time_extraction\n",
        "logger.info(f\"Extra√ß√£o do caso conclu√≠da em {elapsed_time_extraction:.2f}s com {extraction_errors} erro(s).\")\n",
        "\n",
        "if extraction_errors > 0:\n",
        "     print(f\"\\n‚ö†Ô∏è Aten√ß√£o: {extraction_errors} erro(s) ocorreram durante a extra√ß√£o do caso.\")\n",
        "\n",
        "total_probe_extracted = len(probe_embeddings_output[probe_speaker_id])\n",
        "total_ref_extracted = len(reference_embeddings_output[ref_speaker_id])\n",
        "print(\"\\n‚úÖ Extra√ß√£o de embeddings do caso conclu√≠da!\")\n",
        "print(f\"   - {total_probe_extracted} embeddings extra√≠dos dos √°udios questionados do caso.\")\n",
        "print(f\"   - {total_ref_extracted} embeddings extra√≠dos dos √°udios de refer√™ncia do caso.\")\n",
        "\n",
        "# --- 6. Salvar Resultados ---\n",
        "# Pegar os caminhos de sa√≠da definidos na config para os embeddings do CASO\n",
        "output_embeddings_dir = paths_config.get(\"embeddings_dir\", \"files/generated/case/embeddings\")\n",
        "os.makedirs(output_embeddings_dir, exist_ok=True)\n",
        "# Estes s√£o os nomes de arquivo padr√£o para os embeddings do CASO\n",
        "output_probe_emb_file_caso = paths_config.get(\"probe_embeddings_file\", os.path.join(output_embeddings_dir,\"probe_embeddings.pt\"))\n",
        "output_ref_emb_file_caso = paths_config.get(\"reference_embeddings_file\", os.path.join(output_embeddings_dir,\"reference_embeddings.pt\"))\n",
        "\n",
        "logger.info(f\"Salvando embeddings do caso em {output_embeddings_dir}...\")\n",
        "try:\n",
        "    torch.save(probe_embeddings_output, output_probe_emb_file_caso)\n",
        "    logger.info(f\"Embeddings Questionados do caso salvos em: {output_probe_emb_file_caso}\")\n",
        "    torch.save(reference_embeddings_output, output_ref_emb_file_caso)\n",
        "    logger.info(f\"Embeddings Refer√™ncia do caso salvos em: {output_ref_emb_file_caso}\")\n",
        "    print(f\"   - Arquivos de embeddings do caso salvos em: {output_embeddings_dir}\")\n",
        "\n",
        "    # Salvar caminhos para a c√©lula de an√°lise final (C√©lula 8)\n",
        "    # Usa os nomes distintos com _caso\n",
        "    %store output_probe_emb_file_caso\n",
        "    %store output_ref_emb_file_caso\n",
        "    logger.info(\"Caminhos dos arquivos de embeddings do caso salvos.\")\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(f\"Erro ao salvar arquivos de embeddings .pt do caso: {e}\", exc_info=True)\n",
        "    print(f\"\\n‚ùå Erro ao salvar arquivos de embeddings do caso.\")\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QE_JtqfEe-48"
      },
      "outputs": [],
      "source": [
        "# @title (C√©lula 8) An√°lise Final e Plotagem\n",
        "# @markdown Compara os embeddings do caso com os de refer√™ncia populacional e visualiza os resultados.\n",
        "\n",
        "import os\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from pathlib import Path\n",
        "from svforensics import config\n",
        "\n",
        "# Usar o logger configurado\n",
        "logger = logging.getLogger(\"SVF_Colab_Analysis_Final\")\n",
        "\n",
        "# --- 1. Recuperar Vari√°veis Salvas ---\n",
        "logger.info(\"Recuperando vari√°veis salvas...\")\n",
        "try:\n",
        "    %store -r output_probe_emb_file_caso\n",
        "    %store -r output_ref_emb_file_caso\n",
        "    %store -r generated_testlist_path\n",
        "    %store -r output_merged_file\n",
        "    %store -r svf_config\n",
        "    %store -r paths_config\n",
        "    logger.info(\"Vari√°veis recuperadas com sucesso.\")\n",
        "except KeyError as e:\n",
        "     raise RuntimeError(f\"Erro: Vari√°vel essencial '{e}' n√£o encontrada. Execute as c√©lulas anteriores.\")\n",
        "\n",
        "# --- 2. Importar Fun√ß√µes Necess√°rias ---\n",
        "logger.info(\"Importando fun√ß√µes de verifica√ß√£o/an√°lise...\")\n",
        "try:\n",
        "    from svforensics.verification import (\n",
        "        load_test_embeddings, calculate_test_scores, analyze_scores_distribution,\n",
        "        compare_case_embeddings, plot_results, interpret_results # interpret_results ainda √© importado, mas n√£o usado para print\n",
        "    )\n",
        "    logger.info(\"Fun√ß√µes importadas com sucesso.\")\n",
        "except ImportError as e:\n",
        "    raise RuntimeError(f\"Erro ao importar de svforensics.verification: {e}. Verifique a instala√ß√£o.\")\n",
        "\n",
        "# --- 3. Definir Par√¢metros e Validar Entradas ---\n",
        "logger.info(\"Definindo par√¢metros e verificando arquivos de entrada...\")\n",
        "test_list_path = generated_testlist_path\n",
        "processed_embeddings_file = output_merged_file\n",
        "probe_embeddings_file = output_probe_emb_file_caso\n",
        "reference_embeddings_file = output_ref_emb_file_caso\n",
        "\n",
        "use_population_data = False\n",
        "if test_list_path and os.path.exists(test_list_path):\n",
        "    if processed_embeddings_file and os.path.exists(processed_embeddings_file):\n",
        "        logger.info(f\"Usando dados populacionais: Lista={test_list_path}, Embeddings={processed_embeddings_file}\")\n",
        "        use_population_data = True\n",
        "    else:\n",
        "        logger.warning(f\"Lista de teste encontrada ({test_list_path}), mas arquivo de embeddings processados da popula√ß√£o n√£o ({processed_embeddings_file}). An√°lise populacional desativada.\")\n",
        "else:\n",
        "    logger.warning(f\"Lista de teste populacional n√£o encontrada ou n√£o definida ({test_list_path}). An√°lise populacional desativada.\")\n",
        "\n",
        "use_case_data = False\n",
        "if probe_embeddings_file and reference_embeddings_file and \\\n",
        "   os.path.exists(probe_embeddings_file) and os.path.exists(reference_embeddings_file):\n",
        "    logger.info(f\"Usando dados do caso: Probe={probe_embeddings_file}, Ref={reference_embeddings_file}\")\n",
        "    use_case_data = True\n",
        "else:\n",
        "    logger.warning(f\"Arquivos de embeddings do caso n√£o encontrados (Probe: {probe_embeddings_file}, Ref: {reference_embeddings_file}). An√°lise do caso desativada.\")\n",
        "\n",
        "if not use_population_data and not use_case_data:\n",
        "    raise RuntimeError(\"Nenhum dado v√°lido encontrado para an√°lise.\")\n",
        "\n",
        "output_plot_file = paths_config.get(\"case_analysis_plot\", \"files/plots/case_analysis.png\")\n",
        "os.makedirs(Path(output_plot_file).parent, exist_ok=True)\n",
        "plot_config_path = config_paths.get(\"plot_config.json\", config.DEFAULT_PLOT_CONFIG_PATH) # Usar o caminho baixado\n",
        "logger.info(f\"Usando configura√ß√£o de plot: {plot_config_path}\")\n",
        "language = config.get_default_language(config=svf_config)\n",
        "show_progress = True\n",
        "logger.info(f\"Idioma para plotagem: {language}\")\n",
        "\n",
        "# --- 4. Executar An√°lise Populacional (se aplic√°vel) ---\n",
        "same_speaker_stats = {\"count\": 0, \"scores\": [], \"mean\": None, \"std\": None, \"min\": None, \"max\": None, \"median\": None}\n",
        "diff_speaker_stats = {\"count\": 0, \"scores\": [], \"mean\": None, \"std\": None, \"min\": None, \"max\": None, \"median\": None}\n",
        "\n",
        "if use_population_data:\n",
        "    logger.info(\"Iniciando an√°lise populacional...\")\n",
        "    # Manter print de status\n",
        "    print(\"\\n‚è≥ Calculando scores da popula√ß√£o de refer√™ncia...\")\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        pop_embeddings, test_pairs = load_test_embeddings(test_list_path, processed_embeddings_file)\n",
        "        if pop_embeddings:\n",
        "            pop_results = calculate_test_scores(pop_embeddings, test_pairs, show_progress)\n",
        "            same_speaker_stats, diff_speaker_stats = analyze_scores_distribution(pop_results)\n",
        "            elapsed_time = time.time() - start_time\n",
        "            logger.info(f\"An√°lise populacional conclu√≠da em {elapsed_time:.2f}s.\")\n",
        "            print(\"‚úÖ An√°lise populacional conclu√≠da.\") # Manter\n",
        "        else:\n",
        "            logger.warning(\"N√£o foi poss√≠vel carregar embeddings da popula√ß√£o.\")\n",
        "            print(\"‚ö†Ô∏è Embeddings da popula√ß√£o n√£o carregados.\") # Manter\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Erro na an√°lise populacional: {e}\", exc_info=True)\n",
        "        print(\"‚ùå Erro durante a an√°lise populacional.\") # Manter\n",
        "\n",
        "# --- 5. Executar An√°lise do Caso (se aplic√°vel) ---\n",
        "case_results = None\n",
        "if use_case_data:\n",
        "    logger.info(\"Iniciando an√°lise do caso...\")\n",
        "    # Manter print de status\n",
        "    print(\"\\n‚è≥ Comparando embeddings do caso...\")\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        case_results = compare_case_embeddings(\n",
        "            probe_embeddings_file, reference_embeddings_file, show_progress=show_progress\n",
        "        )\n",
        "        elapsed_time = time.time() - start_time\n",
        "        logger.info(f\"An√°lise do caso conclu√≠da em {elapsed_time:.2f}s.\")\n",
        "        print(\"‚úÖ Compara√ß√£o do caso conclu√≠da.\") # Manter\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Erro na an√°lise do caso: {e}\", exc_info=True)\n",
        "        print(\"‚ùå Erro durante a compara√ß√£o do caso.\") # Manter\n",
        "\n",
        "# --- 6. Gerar Plot ---\n",
        "logger.info(\"Gerando o gr√°fico...\")\n",
        "# Manter print de status\n",
        "print(\"\\nüìä Gerando gr√°fico...\")\n",
        "plot_generated = False\n",
        "try:\n",
        "    plot_results(\n",
        "        same_speaker_stats=same_speaker_stats,\n",
        "        diff_speaker_stats=diff_speaker_stats,\n",
        "        case_results=case_results,\n",
        "        output_file=output_plot_file,\n",
        "        config_path=plot_config_path,\n",
        "        language=language\n",
        "    )\n",
        "    if os.path.exists(output_plot_file):\n",
        "        plot_generated = True\n",
        "        logger.info(f\"Gr√°fico salvo em {output_plot_file}\")\n",
        "        print(f\"‚úÖ Gr√°fico salvo em {output_plot_file}\") # Manter\n",
        "    else:\n",
        "         logger.warning(\"Fun√ß√£o plot_results executada, mas arquivo de plot n√£o encontrado.\")\n",
        "         print(\"‚ö†Ô∏è Arquivo de gr√°fico n√£o foi criado.\") # Manter\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(f\"Erro ao gerar o gr√°fico: {e}\", exc_info=True)\n",
        "    print(\"‚ùå Erro durante a gera√ß√£o do gr√°fico.\") # Manter\n",
        "\n",
        "# --- 7. Exibir Plot e Interpreta√ß√£o ---\n",
        "if plot_generated:\n",
        "    logger.info(\"Exibindo o gr√°fico gerado...\")\n",
        "    from IPython.display import Image, display\n",
        "    display(Image(filename=output_plot_file))\n",
        "else:\n",
        "    # Manter aviso se n√£o plotou\n",
        "    print(\"\\n‚ö†Ô∏è O gr√°fico n√£o p√¥de ser exibido.\")\n",
        "\n",
        "# <<<<< REMOVIDA A SE√á√ÉO DE INTERPRETA√á√ÉO >>>>>\n",
        "# print(\"\\n--- Interpreta√ß√£o dos Resultados ---\")\n",
        "# final_results_for_interpretation = {\n",
        "#     \"same_speaker\": same_speaker_stats,\n",
        "#     \"different_speaker\": diff_speaker_stats,\n",
        "#     \"case_results\": case_results,\n",
        "#     \"plot_file\": output_plot_file if plot_generated else None\n",
        "# }\n",
        "# interpretation_text = interpret_results(final_results_for_interpretation)\n",
        "# print(interpretation_text)\n",
        "# print(\"------------------------------------\")\n",
        "\n",
        "# Manter mensagem final de sucesso\n",
        "print(\"\\nüéâ An√°lise conclu√≠da!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
